{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Keras\n",
    "\n",
    "[Jian Tao](https://orcid.org/0000-0003-4228-6089), Texas A&M University\n",
    "\n",
    "Oct 2, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning (DL) is one cagegory of machine learning methods that are based on artificial neural networks to improve computer algorithms automatically through data.\n",
    "\n",
    "DL methods can be devided into:\n",
    "\n",
    "* Supervised Learning\n",
    "    * trained with labeled data; including regression and classification problems\n",
    "* Unsupervised Learning\n",
    "    * trained with unlabeled data; clustering and association rule learning problems.\n",
    "* Reinforcement Learning\n",
    "    * no training data; stochastic Markov decision process; robotics and self-driving cars.\n",
    "\n",
    "DL methods are useful primarily for the following reasons:\n",
    "\n",
    "* DL is computationally expensive, but it is capable of handling high dimensional data.\n",
    "* feature extraction is done automatically.\n",
    "\n",
    "![Deep Learning](./images/deeplearning.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras\n",
    "Keras is an open-source neural-network library written in Python. It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit (CNTK), or Theano.\n",
    "* Designed for fast experimentation with deep neural networks;\n",
    "* Focuses on being user-friendly, modular, and extensible;\n",
    "* TensorFlow 2.X adopted almost entirely Keras APIs and the TensorFlow backend (tf.keras) was recommended as the major release of * multi-backend Keras ceased at Version 2.3.0.\n",
    "* Keras -> tf.keras in the future.\n",
    "![Keras Workflow](./images/keras_workflow.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data points to be fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype = float)\n",
    "y = 3.0 * x + 2.0 + 0.5 * np.random.randn(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y);\n",
    "plt.plot(x, 3*x+2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Linear Regression with scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "sk_model = LinearRegression()\n",
    "\n",
    "# use the data points defined above\n",
    "sk_x = x[:, np.newaxis]\n",
    "sk_y = y\n",
    "\n",
    "# fit the model with sklearn\n",
    "sk_model.fit(sk_x, sk_y);\n",
    "\n",
    "# make predictions\n",
    "sk_yfit = sk_model.predict(sk_x)\n",
    "\n",
    "# plot the fitted line with the equation\n",
    "plt.scatter(sk_x,sk_y);\n",
    "plt.plot(sk_x, sk_yfit);\n",
    "plt.text(-1.0, 15, r\"Y = %f *x + %f\"%(sk_model.coef_, sk_model.intercept_), fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Dense(units=1, input_shape=[1]))\n",
    "model.compile (optimizer='sgd', loss='mean_squared_error')\n",
    "model.fit(x,y,epochs=500, verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,yfit);\n",
    "plt.plot(x, yfit);\n",
    "plt.text(-1.0, 15, r\"Y = %f *x + %f\"%(tuple(model.get_weights())), fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classify Handwritten Digits with Keras\n",
    "Layers are the fundamental building blocks of Keras models. A wide variety of Keras functions are dedicated to create different kind of layers and connect them to form a deep learning network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils, callbacks, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first image in the data set\n",
    "#plt.imshow(x_train[0], cmap=\"gray\") # Import the image\n",
    "#plt.show() # Plot the image\n",
    "\n",
    "# show the first 15 images in the data set.\n",
    "fig = plt.figure()\n",
    "for i in range(15):\n",
    "  plt.subplot(3,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(x_train[i], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Digit: {}\".format(y_train[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the train dataset\n",
    "x_train = utils.normalize(x_train, axis=1)\n",
    "# Normalize the test dataset\n",
    "x_test = utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model object\n",
    "model = Sequential()\n",
    "# Add the Flatten Layer\n",
    "model.add(Flatten())\n",
    "# Build the input and the hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Build the output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for loading Tensorboard.\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs=1, callbacks=[tensorboard_callback]) # Start training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance\n",
    "test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "# Print out the model accuracy \n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model into MNIST.h5 and we are all done with the training now.\n",
    "model.save('MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that plots a single image.\n",
    "def test_digit(i):\n",
    "  plt.imshow(x_test[i], interpolation='none')\n",
    "  plt.title(\"digit:%d   prediction: %d\" %(y_test[i], np.argmax(predictions[i])))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's output the images which were not predicted correctly.\n",
    "for i in range(len(x_test)):\n",
    "    if np.argmax(predictions[i]) != y_test[i]:\n",
    "        test_digit(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
